OLLAMA_URL = "http://localhost:11434"   # make this an env variable
OLLAMA_MODEL = "llama3.2"               # make this an env variable
VERBA_URL = "http://localhost:8000"     # make this an env variable
DB_TYPE = "Docker"
WEAVIATE_URL="" # This needs to be an empty string, or needs to be the url in case of cloud weaviate instance
WEAVIATE_KEY="" # This needs to be an empty string, or needs to be the key in case of cloud weaviate instance
EMBEDDER = "SentenceTransformers"
EMBEDDING_MODEL = "all-MiniLM-L6-v2"

# NOTE THAT THE EMBEDDING MODEL SHOULD MATCH THE OLLAMA EMBEDDING MODEL SELECTED WHILE INDEXING

 # # VLLM Services
    # VLLM_URL_FOR_ANALYSIS=http://vllmnemotrontext:8001/v1/chat/completions

    # # VLLM Models
    # VLLM_MODEL_FOR_ANALYSIS=AMead10/Llama-3.2-3B-Instruct-AWQ

    #############OLLAMA PARAMS###################
    OLLAMA_MODEL_FOR_ANALYSIS = "llama3.2"            
