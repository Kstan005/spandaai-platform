{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'D:\\spanda-ft-work\\repos\\platform-env-fix\\spandaai-platform\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-6.0.0-py3-none-any.whl (14.8 MB)\n",
      "Requirement already satisfied: packaging in d:\\spanda-ft-work\\repos\\platform-env-fix\\spandaai-platform\\venv\\lib\\site-packages (from plotly) (24.2)\n",
      "Collecting narwhals>=1.15.1\n",
      "  Downloading narwhals-1.27.1-py3-none-any.whl (308 kB)\n",
      "Installing collected packages: narwhals, plotly\n",
      "Successfully installed narwhals-1.27.1 plotly-6.0.0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "%pip install plotly\n",
    "\n",
    "import asyncio\n",
    "import websockets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import plotly.express as px\n",
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "import aiohttp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BASE_URL = \"http://localhost:8090/api\"\n",
    "WS_URL = \"ws://localhost:8090/api/ws/document_analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveLearningAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.session = aiohttp.ClientSession()\n",
    "        self.analysis_cache = {}\n",
    "        \n",
    "    async def analyze_document_stream(self, content: str, rubric: dict) -> dict:\n",
    "        \"\"\"Streams document analysis using WebSocket connection\"\"\"\n",
    "        async with websockets.connect(WS_URL) as websocket:\n",
    "            await websocket.send(json.dumps({\n",
    "                \"rubric\": rubric,\n",
    "                \"pre_analysis\": {\n",
    "                    \"degree\": \"PhD\",\n",
    "                    \"name\": \"Analysis Stream\",\n",
    "                    \"topic\": \"Adaptive Learning\",\n",
    "                    \"pre_analyzed_summary\": content[:500]\n",
    "                },\n",
    "                \"feedback\": \"Detailed analysis needed\"\n",
    "            }))\n",
    "            \n",
    "            results = []\n",
    "            async for message in websocket:\n",
    "                data = json.loads(message)\n",
    "                if data[\"type\"] == \"result\":\n",
    "                    return data[\"data\"]\n",
    "                elif data[\"type\"] == \"progress\":\n",
    "                    print(f\"Progress: {data['data']['percentage']}% - {data['data']['message']}\")\n",
    "                    results.append(data['data'])\n",
    "            return results\n",
    "\n",
    "    async def process_content_chunks(self, content: str, chunk_size: int = 1000) -> List[dict]:\n",
    "        \"\"\"Process content in chunks for parallel analysis\"\"\"\n",
    "        async with self.session.post(f\"{BASE_URL}/chunk-text\", \n",
    "                                   json={\"text\": content, \"chunk_size\": chunk_size, \"overlap\": 100}) as response:\n",
    "            chunks = await response.json()\n",
    "            \n",
    "        # Process chunks in parallel\n",
    "        async with self.session.post(f\"{BASE_URL}/process-chunks\", \n",
    "                                   json={\n",
    "                                       \"chunks\": [chunk[\"text\"] for chunk in chunks[\"chunks\"]],\n",
    "                                       \"system_prompt\": \"Analyze for key concepts and learning objectives\",\n",
    "                                       \"batch_size\": 5\n",
    "                                   }) as response:\n",
    "            return await response.json()\n",
    "\n",
    "    async def generate_adaptive_questions(self, content: str, difficulty_distribution: Dict[str, float]) -> List[dict]:\n",
    "        \"\"\"Generate questions with adaptive difficulty based on content analysis\"\"\"\n",
    "        questions = []\n",
    "        difficulties = [\"easy\", \"medium\", \"hard\"]\n",
    "        \n",
    "        for difficulty in difficulties:\n",
    "            count = int(difficulty_distribution[difficulty] * 10)  # 10 questions per difficulty level\n",
    "            async with self.session.post(f\"{BASE_URL}/questions_generation\",\n",
    "                                       json={\n",
    "                                           \"topic\": \"Adaptive Learning\",\n",
    "                                           \"difficulty\": difficulty,\n",
    "                                           \"type_of_question\": \"multiple_choice\",\n",
    "                                           \"no_of_questions\": count,\n",
    "                                           \"context\": content,\n",
    "                                           \"no_of_options\": 4,\n",
    "                                           \"numericality\": \"mixed\",\n",
    "                                           \"few_shot\": \"true\"\n",
    "                                       }) as response:\n",
    "                result = await response.json()\n",
    "                questions.extend(result[\"questions\"])\n",
    "        \n",
    "        return questions\n",
    "\n",
    "    def calculate_learning_path(self, analysis_results: dict, questions: List[dict]) -> Tuple[List[dict], float]:\n",
    "        \"\"\"Calculate optimal learning path based on analysis and questions\"\"\"\n",
    "        # Create knowledge graph from analysis\n",
    "        knowledge_points = {}\n",
    "        for chunk in analysis_results[\"processed_chunks\"]:\n",
    "            for point in chunk[\"key_points\"]:\n",
    "                if point not in knowledge_points:\n",
    "                    knowledge_points[point] = {\n",
    "                        \"difficulty\": np.random.random(),  # Simulate difficulty rating\n",
    "                        \"relevance\": np.random.random(),   # Simulate relevance score\n",
    "                        \"questions\": []\n",
    "                    }\n",
    "        \n",
    "        # Associate questions with knowledge points\n",
    "        for question in questions:\n",
    "            # Simulate matching questions to knowledge points\n",
    "            matched_point = np.random.choice(list(knowledge_points.keys()))\n",
    "            knowledge_points[matched_point][\"questions\"].append(question)\n",
    "        \n",
    "        # Calculate optimal path\n",
    "        sorted_points = sorted(knowledge_points.items(), \n",
    "                             key=lambda x: (x[1][\"difficulty\"], -x[1][\"relevance\"]))\n",
    "        \n",
    "        learning_path = []\n",
    "        total_difficulty = 0\n",
    "        \n",
    "        for point, data in sorted_points:\n",
    "            path_item = {\n",
    "                \"concept\": point,\n",
    "                \"difficulty\": data[\"difficulty\"],\n",
    "                \"relevance\": data[\"relevance\"],\n",
    "                \"questions\": data[\"questions\"]\n",
    "            }\n",
    "            learning_path.append(path_item)\n",
    "            total_difficulty += data[\"difficulty\"]\n",
    "        \n",
    "        return learning_path, total_difficulty / len(sorted_points)\n",
    "\n",
    "    async def visualize_learning_path(self, learning_path: List[dict]):\n",
    "        \"\"\"Create interactive visualization of learning path\"\"\"\n",
    "        df = pd.DataFrame([\n",
    "            {\n",
    "                \"concept\": item[\"concept\"][:50] + \"...\",  # Truncate for display\n",
    "                \"difficulty\": item[\"difficulty\"],\n",
    "                \"relevance\": item[\"relevance\"],\n",
    "                \"question_count\": len(item[\"questions\"])\n",
    "            }\n",
    "            for item in learning_path\n",
    "        ])\n",
    "        \n",
    "        fig = px.scatter(df, x=\"difficulty\", y=\"relevance\",\n",
    "                        size=\"question_count\",\n",
    "                        hover_data=[\"concept\"],\n",
    "                        title=\"Learning Path Visualization\")\n",
    "        \n",
    "        return fig\n",
    "\n",
    "    async def analyze_and_create_path(self, content: str):\n",
    "        \"\"\"Main function to analyze content and create adaptive learning path\"\"\"\n",
    "        # Initial document analysis\n",
    "        analysis_result = await self.analyze_document_stream(content, {\n",
    "            \"learning_objectives\": {\n",
    "                \"criteria_explanation\": \"Clear learning objectives\",\n",
    "                \"score_explanation\": \"Score based on clarity and measurability\",\n",
    "                \"criteria_output\": \"Detailed output format\"\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # Process content in chunks\n",
    "        chunk_results = await self.process_content_chunks(content)\n",
    "        \n",
    "        # Generate adaptive questions\n",
    "        questions = await self.generate_adaptive_questions(\n",
    "            content,\n",
    "            {\"easy\": 0.3, \"medium\": 0.4, \"hard\": 0.3}\n",
    "        )\n",
    "        \n",
    "        # Calculate learning path\n",
    "        learning_path, avg_difficulty = self.calculate_learning_path(chunk_results, questions)\n",
    "        \n",
    "        # Visualize results\n",
    "        viz = await self.visualize_learning_path(learning_path)\n",
    "        \n",
    "        return {\n",
    "            \"analysis\": analysis_result,\n",
    "            \"learning_path\": learning_path,\n",
    "            \"visualization\": viz,\n",
    "            \"average_difficulty\": avg_difficulty,\n",
    "            \"question_count\": len(questions)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage Example\n",
    "async def main():\n",
    "    analyzer = AdaptiveLearningAnalyzer()\n",
    "    \n",
    "    # Sample content\n",
    "    content = \"\"\"\n",
    "    [Your educational content here...]\n",
    "    \"\"\"\n",
    "    \n",
    "    results = await analyzer.analyze_and_create_path(content)\n",
    "    \n",
    "    # Display results\n",
    "    display(HTML(\"<h2>Analysis Results</h2>\"))\n",
    "    display(results[\"visualization\"])\n",
    "    print(f\"\\nAverage Difficulty: {results['average_difficulty']:.2f}\")\n",
    "    print(f\"Total Questions Generated: {results['question_count']}\")\n",
    "    \n",
    "    for i, path_item in enumerate(results[\"learning_path\"], 1):\n",
    "        print(f\"\\nStep {i}: {path_item['concept']}\")\n",
    "        print(f\"Difficulty: {path_item['difficulty']:.2f}\")\n",
    "        print(f\"Relevance: {path_item['relevance']:.2f}\")\n",
    "        print(f\"Questions: {len(path_item['questions'])}\")\n",
    "\n",
    "# Run the analysis\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
