{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de05df2e",
   "metadata": {},
   "source": [
    "# vLLM FastAPI API Calls Notebook\n",
    "\n",
    "This notebook demonstrates how to interact with the FastAPI endpoints for managing vLLM containers. We will:\n",
    "\n",
    "1. Start a vLLM container with specified parameters\n",
    "2. Check the container status\n",
    "3. Stop the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9eaac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Base URL for the FastAPI server\n",
    "BASE_URL = \"http://localhost:7500\"\n",
    "\n",
    "# Define the model name and HF token to be used in the requests\n",
    "MODEL_NAME = \"HuggingFaceTB/SmolLM-135M\"\n",
    "HF_TOKEN = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa2f9f",
   "metadata": {},
   "source": [
    "## Start vLLM Container\n",
    "\n",
    "This cell calls the `/start-vllm` endpoint to start a vLLM container with extra command arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e2c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the payload with extra command arguments\n",
    "payload = {\n",
    "    \"hf_token\": HF_TOKEN,\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"command\": \"--max-num-seqs 256 --max-num-batched-tokens 16384 --gpu-memory-utilization 0.1 --swap-space 8 --disable-custom-all-reduce --use-v2-block-manager --enable-chunked-prefill --enable-prefix-caching --enforce-eager\"\n",
    "}\n",
    "\n",
    "start_url = f\"{BASE_URL}/start-vllm\"\n",
    "response = requests.post(start_url, json=payload)\n",
    "\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(\"Response:\", response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a2ec8f",
   "metadata": {},
   "source": [
    "## Check vLLM Container Status\n",
    "\n",
    "This cell calls the `/status-vllm` endpoint to check the status of the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a30c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_url = f\"{BASE_URL}/status-vllm\"\n",
    "params = {\"model_name\": MODEL_NAME}\n",
    "response = requests.get(status_url, params=params)\n",
    "\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(\"Response:\", response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1d80a7",
   "metadata": {},
   "source": [
    "## Stop vLLM Container\n",
    "\n",
    "This cell calls the `/stop-vllm` endpoint to stop and remove the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8fbe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_url = f\"{BASE_URL}/stop-vllm\"\n",
    "params = {\"model_name\": MODEL_NAME}\n",
    "response = requests.post(stop_url, params=params)\n",
    "\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(\"Response:\", response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
