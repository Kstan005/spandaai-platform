# API Gateway will run on this port
PORT=8090

# API Gateway Configuration - for microservices - where all microservies will run
DATA_PROCESSING_URL=http://localhost:9001
EDU_AI_AGENTS_URL=http://localhost:9002
WEBSOCKET_SERVICE_URL=ws://localhost:9000


# Platform Services
    # Hugging Face Token for vLLM services
    HF_TOKEN=your_hf_token_here

    # # VLLM Services
    # VLLM_URL_FOR_ANALYSIS=http://vllmnemotrontext:8001/v1/chat/completions
    # VLLM_URL_FOR_SUMMARY=http://vllmnemotrontext:8001/v1/chat/completions
    # VLLM_URL_FOR_IMAGE=http://vllmqwenvision:8002/v1/chat/completions
    # VLLM_URL_FOR_SCORING=http://vllmnemotrontext:8001/v1/chat/completions
    # VLLM_URL_FOR_EXTRACTION=http://vllmnemotrontext:8001/v1/chat/completions

    # # VLLM Models
    # VLLM_MODEL_FOR_ANALYSIS=AMead10/Llama-3.2-3B-Instruct-AWQ
    # VLLM_MODEL_FOR_EXTRACTION=AMead10/Llama-3.2-3B-Instruct-AWQ
    # VLLM_MODEL_FOR_SUMMARY=AMead10/Llama-3.2-3B-Instruct-AWQ
    # VLLM_MODEL_FOR_IMAGE=Qwen/Qwen2-VL-2B-Instruct-AWQ
    # VLLM_MODEL_FOR_SCORING=AMead10/Llama-3.2-3B-Instruct-AWQ

    #############OLLAMA PARAMS###################
    OLLAMA_URL = "http://localhost:11434"
    OLLAMA_MODEL_FOR_ANALYSIS = "llama3.2"            
    OLLAMA_MODEL_FOR_EXTRACTION = "llama3.2"            
    OLLAMA_MODEL_FOR_SUMMARY = "llama3.2"            
    OLLAMA_MODEL_FOR_IMAGE = "llava-phi3"
    OLLAMA_MODEL_FOR_SCORING = "llama3.2"

VERBA_URL = "http://localhost:8000"     # make this an env variable
DB_TYPE = "Docker"
WEAVIATE_URL="" # This needs to be an empty string, or needs to be the url in case of cloud weaviate instance
WEAVIATE_KEY="" # This needs to be an empty string, or needs to be the key in case of cloud weaviate instance
EMBEDDER = "SentenceTransformers"
EMBEDDING_MODEL = "all-MiniLM-L6-v2"